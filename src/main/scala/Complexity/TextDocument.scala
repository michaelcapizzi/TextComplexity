package Complexity

import edu.arizona.sista.struct.Counter
import java.util
import TextDocument._

import scala.collection.parallel.ParSeq


/**
  * Class to house all the NLP elements for an entire document.
  * Consists of [[ProcessedParagraph]]s for each paragraph of the document.
  * Will be fed to individual Feature classes.
  * @param paragraphs `Vector` of '''annotated''' [[ProcessedParagraph]]s
  * @param title Optional title of document
  * @param author Optional author of document
  * @param gradeLevel Optional grade level of document
  */
class TextDocument (
                    val paragraphs: Vector[ProcessedParagraph],    //already annotated!
                    val title: Option[String] = None,
                    val author: Option[String] = None,
                    val gradeLevel: Option[String] = None
                   ){

  /**
    * Parallelized `Vector` of paragraphs for operations that can benefit from parallelization.  '''Note: This does not include annotating!'''
     */
  val parParagraphs = this.paragraphs.par

  /**
    * All counters generated by [[ProcessedParagraph.buildCounters]]
     */
  val allCounters = this.parParagraphs.map(_.buildCounters)
  /**
    * All `Counter[String]`s generated by [[ProcessedParagraph.buildCounters]]
    */
  val stringCounters = allCounters.map(_._1)
  /**
    * All `Counter[(String, String)]`s generated by [[ProcessedParagraph.buildCounters]]
    */
  val stringStringCounters = allCounters.map(_._2)

  /**
    * Uses [[TextDocument.foldApply]] to collapse each [[ProcessedParagraph]]'s `Counter` into one counter
    */
  val tokensCounter = foldApply[Counter[String]](
                        stringCounters.map(_("tokens")),
                        new Counter[String](),
                        (a: Counter[String], b: Counter[String]) => a + b
                      )

  /**
    * Uses [[TextDocument.foldApply]] to collapse each [[ProcessedParagraph]]'s `Counter` into one counter
    */
  val lemmasCounter = foldApply[Counter[String]](
                        stringCounters.map(_("lemmas")),
                        new Counter[String](),
                        (a: Counter[String], b: Counter[String]) => a + b
                      )

  /**
    * Uses [[TextDocument.foldApply]] to collapse each [[ProcessedParagraph]]'s `Counter` into one counter
    */
  val tagsCounter = foldApply[Counter[String]](
                        stringCounters.map(_("tags")),
                        new Counter[String](),
                        (a: Counter[String], b: Counter[String]) => a + b
                      )

  /**
    * Uses [[TextDocument.foldApply]] to collapse each [[ProcessedParagraph]]'s `Counter` into one counter
    */
  val tokensTagsCounter = foldApply[Counter[(String, String)]](
                        stringStringCounters.map(_("tokens-tags")),
                        new Counter[(String, String)](),
                        (a: Counter[(String, String)], b: Counter[(String, String)]) => a + b
                      )
  /**
    * Uses [[TextDocument.foldApply]] to collapse each [[ProcessedParagraph]]'s `Counter` into one counter
    */
  val lemmasTagsCounter = foldApply[Counter[(String, String)]](
                        stringStringCounters.map(_("lemmas-tags")),
                        new Counter[(String, String)](),
                        (a: Counter[(String, String)], b: Counter[(String, String)]) => a + b
                      )
  /**
    * Uses [[TextDocument.foldApply]] to collapse each [[ProcessedParagraph]]'s `Counter` into one counter
    */
  val properNounsCounter = foldApply[Counter[String]](
                        stringCounters.map(_("proper nouns")),
                        new Counter[String](),
                        (a: Counter[String], b: Counter[String]) => a + b
                      )


  /**
    *
    * @param POS `noun`, `adjective`, `verb`, `adverb`, defaults to `noun`
    * @param gram `word` or `lemma`
    * @return `._1` = the `word` or `lemma` <br>
    *         `._2` = the `tag`
    */
  //TODO took wrote regex and then only had to do counter steps once
  //TODO initialize variable outside of loop
  def filterCounterByPOS(POS: String, gram: String): Counter[(String, String)] = {
    //initiate regex
    var regex = ""

    POS match {
      case "noun" => regex = "NN.?"
      case "adjective" => regex = "JJ.?"
      case "verb" => regex = "VB.?"
      case "adverb" => regex = "RB.?"
      case _ => regex = "NN.?"
    }

    //filter counter
    gram match {
      case "word" => this.tokensTagsCounter.filter(t => t._1._2.matches(regex))
      case "lemma" => this.lemmasTagsCounter.filter(t => t._1._2.matches(regex))
      case _ => this.tokensTagsCounter.filter(t => t._1._2.matches(regex))
    }
  }

  /**
    * Filters our stop words based on `tag` value <br>
    *   Keeps only `noun`s, `adjective`s, `verb`s, and `adverb`s
    * @param gram `word` or `lemma`
    * @return `._1` = the `word` or `lemma` <br>
    *         `._2` = the `tag`
    */
  def filterStopWords(gram: String): Counter[(String, String)] = {

    val nounCounter = this.filterCounterByPOS("noun", gram)
    val verbCounter = this.filterCounterByPOS("verb", gram)
    val adjCounter = this.filterCounterByPOS("adjective", gram)
    val advCounter = this.filterCounterByPOS("adverb", gram)
    val counterList = ParSeq(nounCounter, verbCounter, adjCounter, advCounter)

    foldApply
      [Counter[(String, String)]](
        counterList,
        new Counter[(String, String)](),
        (a: Counter[(String, String)], b: Counter[(String, String)]) => a + b
      )

  }


  ////////////////NLP items////////////////////

  /**
    * `Vector` of outputs from [[ProcessedParagraph.rawSentences]]
     */
  val rawSentences = this.paragraphs.map(_.rawSentences)

  /**
    *
     * @param withPunctuation Use of `true` will include punctuation as tokens <br> `false` will remove all punctuation from tokens
    * @return `Vector` of outputs from [[ProcessedParagraph.words]]
    */
  def words(withPunctuation: Boolean): Vector[Vector[Vector[String]]] = {
    this.paragraphs.map(_.words(withPunctuation))
  }

  /**
    *
     * @param withPunctuation Use of `true` will include punctuation as tokens <br> `false` will remove all punctuation from tokens
    * @return `Vector` of outputs from [[ProcessedParagraph.lemmas]]
    */
  def lemmas(withPunctuation: Boolean): Vector[Vector[Vector[String]]] = {
    this.paragraphs.map(_.lemmas(withPunctuation))
  }

  /**
    *
    * @param withPunctuation Use of `true` will include punctuation as tokens <br> `false` will remove all punctuation from tokens
    * @return `Vector` of outputs from [[ProcessedParagraph.tags]]
    */
  def tags(withPunctuation: Boolean): Vector[Vector[Vector[String]]] = {
    this.paragraphs.map(_.tags(withPunctuation))
  }

  /**
    *
    * @param withPunctuation Use of `true` will include punctuation as tokens <br> `false` will remove all punctuation from tokens
    * @return `Vector` of outputs from [[ProcessedParagraph.entities]]
    */  def entities(withPunctuation: Boolean): Vector[Vector[Vector[String]]] = {
    this.paragraphs.map(_.entities(withPunctuation))
  }

  /**
    * Generates a tuple of `(word, (lemma, tag, named entity))`
    * @param withPunctuation Use of `true` will include punctuation as tokens <br> `false` will remove all punctuation from tokens
    * @return `Vector` of outputs from [[ProcessedParagraph.lexicalTuple]]
    *         - `._1` = word <br>
    *         - `._2._1` = lemma <br>
    *         - `._2._2` = tag <br>
    *         - `._2._3` = named entity (`O` for none) <br>
    */  def lexicalTuples(withPunctuation: Boolean): Vector[Vector[Vector[(String, (String, String, String))]]] = {
    this.paragraphs.map(_.lexicalTuple(withPunctuation))
  }

  /**
    * SISTA `processors`-generated trees
     * @return `Vector` of outputs from [[ProcessedParagraph.sistaParseTree]]
    */
  def sistaParseTrees: Vector[Vector[edu.arizona.sista.struct.Tree]] = {
    this.paragraphs.map(_.sistaParseTree)
  }

  /**
    * CoreNLP-generated `Tree`s
    * @return `Vector` of outputs from [[ProcessedParagraph.coreNLPParseTree]]
    *  @see [[http://nlp.stanford.edu/nlp/javadoc/javanlp/edu/stanford/nlp/trees/Tree.html]]
    */  def coreNLPParseTrees: Vector[Vector[edu.stanford.nlp.trees.Tree]] = {
    this.paragraphs.map(_.coreNLPParseTree)
  }

  /**
    * CoreNLP-generated `Constituent`s
    * @return `Vector` of outputs from [[ProcessedParagraph.rawConstituents]]
    *  @see [[http://nlp.stanford.edu/nlp/javadoc/javanlp/edu/stanford/nlp/trees/Constituent.html]]
    */  def rawConstituents: Vector[Vector[util.Set[edu.stanford.nlp.trees.Constituent]]] = {
    this.paragraphs.map(_.rawConstituents)
  }

  /**
    * Dependency parse represented in `pretty print` form of a `directed graph`
     * @return `Vector` of outputs from [[ProcessedParagraph.rawDependencies]]
    */
  def dependencies: Vector[Vector[edu.arizona.sista.struct.DirectedGraph[String]]] = {
    this.paragraphs.map(_.rawDependencies)
  }

  /**
    *
     * @return `Vector` of outputs from [[ProcessedParagraph.rawDiscourseParse]]
    */
  def rawDiscourseParses: Vector[edu.arizona.sista.discourse.rstparser.DiscourseTree] = {
    this.paragraphs.map(_.rawDiscourseParse)
  }

  /////////////normalization terms/////////////

  /**
    * Normalization term
    * @param gram `word` or `lemma`
    * @return Number of total `words` or `lemmas` in [[TextDocument]]
    */
  def totalCount(gram: String): Double = {
    gram match {
      case "word" => this.tokensCounter.values.sum
      case "lemma" => this.lemmasCounter.values.sum
      case _ => this.tokensCounter.values.sum
    }
  }

  /**
    * Normalization term
     * @return Number of total `words` in [[TextDocument]] with proper nouns from [[properNounsCounter]] removed
    */
  def totalCountMinusProper: Double = {
    (this.tokensCounter - this.properNounsCounter).values.sum
  }

  /**
    * Normalization term
    * @param gram `word` or `lemma`
    * @return Number of distinct `word` or `lemmas` (types) in [[TextDocument]]
    */
  def distinctCount(gram: String): Double = {
    gram match {
      case "word" => this.tokensCounter.size.toDouble
      case "lemma" => this.lemmasCounter.size.toDouble
      case _ => this.tokensCounter.size.toDouble
    }
  }

  /**
    * Ratio of distinct tokens (types) to all tokens
     * @param gram `word` or `lemma`
    * @return Percentage of all tokens in [[TextDocument]] that is distinct
    */
  def countRatio(gram: String): Double = {
    this.distinctCount(gram) / this.totalCount(gram)
  }


  /**
    * Normalization term
     * @return Number of sentences in [[TextDocument]]
    */
  def totalSentences: Double = {
    this.rawSentences.flatten.length.toDouble
  }


}

/**
  * Contains general functions needed in processing TextDocument
  */
object TextDocument {

  /**
    * Wrapper function to easily apply `foldLeft`
    * @param list Parallelized sequence (use [[TextDocument.parParagraphs]]) to be applied to `foldLeft`
    * @param startingItem The initial value of the function to be applied to `foldLeft`
    * @param function The function to be applied to `foldLeft`
    * @tparam T Can be any type as long as it is consistent throughout method
    * @return Result of `foldLeft` applied to the initial sequence
    * @example Sums all `Counter`s in the sequence
    *          {{{
    *          val tokensCounter = foldApply[Counter[String]](
    *                               stringCounters.map(_("tokens")),
    *                               new Counter[String](),
    *                               (a: Counter[String], b: Counter[String]) => a + b
    *          )
    *          }}}
    */
  //TODO use of Typing
  def foldApply[T](list: scala.collection.parallel.ParSeq[T], startingItem: T, function: (T, T) => T): T = {
    list.foldLeft(startingItem)(function)
  }

  /*//TODO are these needed anymore?
  //fold function for integers
  def foldApplyInt(list: scala.collection.parallel.ParSeq[Int], startingInt: Int, function: (Int, Int) => Int): Int = {
    list.foldLeft(startingInt)(function)
  }

  //fold function for doubles
  def foldApplyDouble(list: scala.collection.parallel.ParSeq[Double], startingDouble: Double, function: (Double, Double) => Double): Double = {
    list.foldLeft(startingDouble)(function)
  }

  //fold function for counters
  def foldApplyCounter(list: scala.collection.parallel.ParSeq[Counter[String]], startingCounter: Counter[String], function: (Counter[String], Counter[String]) => Counter[String]): Counter[String] = {
    list.foldLeft(startingCounter)(function)
  }*/

}
