import Complexity.TextDocument._

//use sbt "testOnly *MyTestSuiteName"

/**
  * Tests for ProcessedParagraph and TextDocument classes
  */
class DocumentTests extends GeneralTest {

  "Imported annotation and annotated imported text" should "be the same" in {
    assert(procParsFromAnnotation.map(_.words(false)) == procParsFromText.map(_.words(false)))
  }


  "TextDocument from plain text and TextDocument from imported annotation" should "be the same" in {
    assert(tdFromText.words(false) == tdFromAnnotation.words(false))
  }


  "Words without punctuation" should "be shorter than words with punctuation" in {
    for (paragraph <- procParsFromText) {
      val withPunct = paragraph.words(withPunctuation = true).flatten
      val withoutPunct = paragraph.words(withPunctuation = false).flatten
      assert(withPunct.length > withoutPunct.length)
    }
  }


  "The proper nouns" should "be Owl and Moon" in {
    assert(tdFromText.properNounsCounter.size == 2)
  }


  /*"The tags counter" should "have the same value whether generated by .foldApply or by .foldApplyCounter" in {
    val tagCounterList = tdFromText.parParagraphs.map(_.buildCounters).map(_._1("tags"))
    val generalFold = foldApply(tagCounterList, new Counter[String], (a: Counter[String],b: Counter[String]) => a + b)
    val counterFold = foldApplyCounter(tagCounterList, new Counter[String], (a,b) => a + b)

    assert(generalFold == counterFold)
  }*/


  "Filtered stop-word counter " should "not contain determiners or conjunctions" in {
    assert(
      !tdFromText.filterStopWords("words").keySet.map(_._2).contains("DT") &&
      !tdFromText.filterStopWords("lemmas").keySet.map(_._2).contains("DT") &&
      !tdFromText.filterStopWords("words").keySet.map(_._2).contains("CC") &&
      !tdFromText.filterStopWords("lemmas").keySet.map(_._2).contains("CC")
    )
  }

}

/**
  * Tests for LexicalFeatures class
  */
class LexicalTests extends GeneralTest {

  "Lexical feature vector" should "compile" in {
    assert(lex.makeLexicalFeatureVector.nonEmpty)
  }


  "Lexical feature vector" should "have normalized values less than one" in {
    val features = lex.makeLexicalFeatureVector

    assert(features.slice(2,9).filter(z => z._2 > 1) == Vector())
  }

}

/**
  * Tests for SyntacticFeatures class
  */
class SyntacticTests extends GeneralTest {

  "Syntactic feature vector" should "compile" in {
    assert(syn.makeSyntacticFeatureVector.nonEmpty)
  }

  "Syntactic method capturing only punctuation" should "not have any alpha-numeric tokens remaining" in {
    assert(syn.getPunctuation.flatten.filter(_.matches("[A-z0-9]+")) == Vector())
  }


  "Ratios of sentence structures" should "be a probability distribution" in {
    val sum = foldApply[Double](
                syn.sentenceStructureTypeStats.toVector.par.map(_._2),
                0d,
                (a: Double, b: Double) => a + b
              )

    assert(sum == 1d)
  }

}

